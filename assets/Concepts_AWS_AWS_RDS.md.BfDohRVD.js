import{A as e,d as t,m as n}from"./chunks/runtime-core.esm-bundler.BXAIOQQS.js";import{t as r}from"./chunks/plugin-vue_export-helper.CtN8rQnz.js";const i=JSON.parse(`{"title":"AWS RDS","description":"AWS RDS","frontmatter":{"title":"AWS RDS","description":"AWS RDS","prev":"./AWS"},"headers":[],"relativePath":"Concepts/AWS/AWS_RDS.md","filePath":"Concepts/AWS/AWS_RDS.md","lastUpdated":1756574703000}`);var a={name:`Concepts/AWS/AWS_RDS.md`};function o(r,i,a,o,s,c){return e(),t(`div`,null,[...i[0]||=[n(`<h1 id="aws-rds-overview" tabindex="-1">AWS RDS Overview <a class="header-anchor" href="#aws-rds-overview" aria-label="Permalink to “AWS RDS Overview”">​</a></h1><ul><li>RDS stands for Relational Database Service</li><li>It&#39;s a managed DB service for DB use SQL as a query language.</li><li>It allows you to create databases in the cloud that are managed by AWS <ul><li>Postgres</li><li>MySQL</li><li>MariaDB</li><li>Oracle</li><li>Microsoft SQL Server</li><li>Aurora (AWS Proprietary database)</li></ul></li></ul><h2 id="advantage-over-using-rds-versus-deploying-db-on-ec2" tabindex="-1">Advantage over using RDS versus deploying DB on EC2 <a class="header-anchor" href="#advantage-over-using-rds-versus-deploying-db-on-ec2" aria-label="Permalink to “Advantage over using RDS versus deploying DB on EC2”">​</a></h2><ul><li>RDS is a managed service: <ul><li>Automated provisioning, OS patching</li><li>Continuous backups and restore to specific timestamp (Point in Time Restore)!</li><li>Monitoring dashboards</li><li>Read replicas for improved read performance</li><li>Multi AZ setup for DR (Disaster Recovery)</li><li>Maintenance windows for upgrades</li><li>Scaling capability (vertical and horizontal)</li><li>Storage backed by EBS (gp2 or io1)</li></ul></li><li>BUT you can&#39;t SSH into your instances</li></ul><h2 id="rds-backups" tabindex="-1">RDS Backups <a class="header-anchor" href="#rds-backups" aria-label="Permalink to “RDS Backups”">​</a></h2><ul><li>Backups are automatically enabled in RDS</li><li>Automated backups: <ul><li>Daily full backup of the database (during the maintenance window)</li><li>Transaction logs are backed-up by RDS every 5 minutes</li><li>=&gt; ability to restore to any point in time (from oldest backup to 5 minutes ago)</li><li>7 days retention (can be increased to 35 days)</li></ul></li><li>DB Snapshots: <ul><li>Manually triggered by the user</li><li>Retention of backup for as long as you want</li></ul></li></ul><h2 id="rds-storage-auto-scaling" tabindex="-1">RDS - Storage Auto Scaling <a class="header-anchor" href="#rds-storage-auto-scaling" aria-label="Permalink to “RDS - Storage Auto Scaling”">​</a></h2><ul><li>Helps you increase storage on your RDS DB instance dynamically</li><li>When RDS detects you are running out of free database storage, it scales automatically</li><li>Avoid manually scaling your database storage</li><li>You have to set Maximum Storage Threshold (maximum limit for DB storage)</li><li>Automatically modify storage if: <ul><li>Free storage is less than 10% of allocated storage</li><li>Low-storage lasts at least 5 minutes</li><li>6 hours have passed since last modification</li></ul></li><li>Useful for applications with unpredictable workloads</li><li>Supports all RDS database engines (MariaDB, MySQL, PostgreSQL, SQL Server, Oracle)</li></ul><h2 id="rds-read-replicas-for-read-scalability" tabindex="-1">RDS Read Replicas for read scalability <a class="header-anchor" href="#rds-read-replicas-for-read-scalability" aria-label="Permalink to “RDS Read Replicas for read scalability”">​</a></h2><ul><li>Up to 5 Read Replicas</li><li>Within AZ, Cross AZ Application or Cross Region</li><li>Replication is ASYNC, so reads are eventually consistent</li><li>Replicas can be promoted to their own DB</li><li>Applications must update the connection string to leverage read replicas</li></ul><h3 id="rds-read-replicas-use-cases" tabindex="-1">RDS Read Replicas - Use Cases <a class="header-anchor" href="#rds-read-replicas-use-cases" aria-label="Permalink to “RDS Read Replicas - Use Cases”">​</a></h3><ul><li>You have a production database that is taking on normal load</li><li>You want to run a reporting application to run some analytics</li><li>You create a Read Replica to run the new workload there</li><li>The production application is unaffected</li><li>Read replicas are used for SELECT (=read) only kind of statements (not INSERT, UPDATE, DELETE)</li></ul><h3 id="rds-read-replicas-network-cost" tabindex="-1">RDS Read Replicas - Network Cost <a class="header-anchor" href="#rds-read-replicas-network-cost" aria-label="Permalink to “RDS Read Replicas - Network Cost”">​</a></h3><ul><li>In AWS there&#39;s a network cost when data goes from one AZ to another</li><li>For RDS Read Replicas within the same region, you don&#39;t pay that fee</li></ul><h2 id="rds-multi-az-disaster-recovery" tabindex="-1">RDS Multi AZ (Disaster Recovery) <a class="header-anchor" href="#rds-multi-az-disaster-recovery" aria-label="Permalink to “RDS Multi AZ (Disaster Recovery)”">​</a></h2><ul><li>SYNC replication</li><li>One DNS name - automatic app failover to standby</li><li>Increase availability</li><li>Failover in case of loss of AZ, loss of network, instance or storage failure</li><li>No manual intervention in apps</li><li>Not used for scaling</li><li>Multi-AZ replication is free</li><li>Note:The Read Replicas be setup as Multi AZ for Disaster Recovery (DR)</li></ul><h3 id="rds-from-single-az-to-multi-az" tabindex="-1">RDS - From Single-AZ to Multi-AZ <a class="header-anchor" href="#rds-from-single-az-to-multi-az" aria-label="Permalink to “RDS - From Single-AZ to Multi-AZ”">​</a></h3><ul><li>Zero downtime operation (no need to stop the DB)</li><li>Just click on &quot;modify&quot; for the database</li><li>The following happens internally: <ul><li>A snapshot is taken</li><li>A new DB is restored from the snapshot in a new AZ</li><li>Synchronization is established between the two databases</li></ul></li></ul><h2 id="create-a-rds" tabindex="-1">Create a RDS <a class="header-anchor" href="#create-a-rds" aria-label="Permalink to “Create a RDS”">​</a></h2><p>Steps:</p><ol><li><p>Goto RDS</p></li><li><p>Create database</p></li><li><p>Choose a database creation method:</p><ul><li>Standard create</li><li>Easy create (uses predefined configurations)</li></ul></li><li><p>Engine options:</p><ul><li>Amazon Aurora (not available in Free-tier)</li><li>MySQL</li><li>MariaDB</li><li>PostgreSQL</li><li>Oracle</li><li>Microsoft SQL Server</li></ul></li><li><p>Select the edition and version of the database</p></li><li><p>Templates:</p><ul><li>Production</li><li>Dev/Test</li><li>Free tier</li></ul></li><li><p>Settings:</p><ul><li>DB instance identifier (unique name)</li><li>Credentials Settings: Master username and password</li></ul></li><li><p>DB Instance class:</p><ul><li>Standard classes (includes m classes)</li><li>Memory optimized classes (includes r and x classes)</li><li>Burstable classes (includes t classes): db.t2.micro (1 vCPUs, 1 GiB RAM, Not EBS Optimized)</li></ul></li><li><p>Storage:</p><ul><li>Storage type (General Purpose (SSD), Provisioned IOPS (SSD), Magnetic)</li><li>Allocated storage (20 GiB)</li><li>Storage autoscaling (increase storage when specified threshold is exceeded)</li></ul></li><li><p>Availability &amp; durability: Multi-AZ deployment</p></li><li><p>Connectivity:</p><ul><li>VPC</li><li>Subnet Group</li><li>Public access</li><li>VPC security group</li><li>Port: 3306</li></ul></li><li><p>Database authentication:</p><ul><li>Password authentication (using database passwords as created in step 7)</li><li>Password and IAM database authentication</li><li>Password and Kerberos authentication</li></ul></li><li><p>Additional configuration:</p><ul><li>Database options: Initial database name</li><li>Backup: Enable automated backups (snapshots)</li><li>Backup retention period (0 - 35 days)</li><li>Backup window (when the backup should happen)</li><li>Monitoring</li><li>Logging to CloudWatch</li><li>Maintenance: Enable auto minor version upgrade</li><li>Deletion protection (protects database from being deleted accidentally)</li></ul></li></ol><h2 id="rds-security-encryption" tabindex="-1">RDS Security - Encryption <a class="header-anchor" href="#rds-security-encryption" aria-label="Permalink to “RDS Security - Encryption”">​</a></h2><ul><li>At rest encryption <ul><li>Possibility to encrypt the master &amp; read replicas with AWS KMS - AES-256 encryption</li><li>Encryption has to be defined at launch time</li><li>If the master is not encrypted, the read replicas cannot be encrypted</li><li>Transparent Data Encryption (TDE) available for Oracle and SQL Server</li></ul></li><li>In-flight encryption <ul><li>SSL certificates to encrypt data to RDS in flight</li><li>Provide SSL options with trust certificate when connecting to database</li><li>To enforce SSL: <ul><li>PostgreSQL: <code>rds.force_ssl=1</code> in the AWS RDS Console (Parameter Groups)</li><li>MySQL: Within the DB: <code>GRANT USAGE ON *.* TO &#39;mysqluser&#39;@&#39;%&#39; REQUIRE SSL;</code></li></ul></li></ul></li></ul><h3 id="rds-encryption-operations" tabindex="-1">RDS Encryption Operations <a class="header-anchor" href="#rds-encryption-operations" aria-label="Permalink to “RDS Encryption Operations”">​</a></h3><ul><li>Encrypting RDS backups <ul><li>Snapshots of un-encrypted RDS databases are un-encrypted</li><li>Snapshots of encrypted RDS databases are encrypted</li><li>Can copy a snapshot into an encrypted one</li></ul></li><li>To encrypt an un-encrypted RDS database: <ul><li>Create a snapshot of the un-encrypted database</li><li>Copy the snapshot and enable encryption for the snapshot</li><li>Restore the database from the encrypted snapshot</li><li>Migrate applications to the new database, and delete the old database</li></ul></li></ul><h3 id="rds-security-network-iam" tabindex="-1">RDS Security - Network &amp; IAM <a class="header-anchor" href="#rds-security-network-iam" aria-label="Permalink to “RDS Security - Network &amp; IAM”">​</a></h3><ul><li>Network Security <ul><li>RDS databases are usually deployed within a private subnet, not in a public one</li><li>RDS security works by leveraging security groups (the same concept as for EC2 instances) - it controls which IP / security group can communicate with RDS</li></ul></li><li>Access Management <ul><li>IAM policies help control who can manage AWS RDS (through the RDS API)</li><li>Traditional Username and Password can be used to login into the database</li><li>IAM-based authentication can be used to login into RDS MySQL &amp; PostgreSQL</li></ul></li></ul><h3 id="rds-iam-authentication" tabindex="-1">RDS - IAM Authentication <a class="header-anchor" href="#rds-iam-authentication" aria-label="Permalink to “RDS - IAM Authentication”">​</a></h3><ul><li>IAM database authentication works with MySQL and PostgreSQL</li><li>You don&#39;t need a password, just an authentication token obtained through IAM &amp; RDS API calls</li><li>Auth token has a lifetime of 15 minutes</li><li>Benefits: <ul><li>Network in/out must be encrypted using SSL</li><li>IAM to centrally manage users instead of DB</li><li>Can leverage IAM Roles and EC2 Instance profiles for easy integration</li></ul></li></ul><h3 id="rds-security-summary" tabindex="-1">RDS Security - Summary <a class="header-anchor" href="#rds-security-summary" aria-label="Permalink to “RDS Security - Summary”">​</a></h3><ul><li>Encryption at rest: <ul><li>Is done only when you first create the DB instance</li><li>or: unencrypted DB =&gt; snapshot =&gt; copy snapshot as encrypted =&gt; create DB from snapshot</li></ul></li><li>Your responsibility: <ul><li>Check the ports / IP / security group inbound rules in DB&#39;s SG</li><li>In-database user creation and permissions or manage through IAM</li><li>Creating a database with or without public access</li><li>Ensure parameter groups or DB is configured to only allow SSL connections</li></ul></li><li>AWS responsibility: <ul><li>No SSH access</li><li>No manual DB patching</li><li>No manual OS patching</li><li>No way to audit the underlying instance</li></ul></li></ul><h2 id="amazon-aurora" tabindex="-1">Amazon Aurora <a class="header-anchor" href="#amazon-aurora" aria-label="Permalink to “Amazon Aurora”">​</a></h2><ul><li>Aurora is a proprietary technology from AWS (not open sourced)</li><li>Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database)</li><li>Aurora is &quot;AWS cloud optimized&quot; and claims 5x performance improvement over MySQL on RDS, over 3x the performance of Postgres on RDS</li><li>Aurora storage automatically grows in increments of 10GB, up to 64 TB.</li><li>Aurora can have 15 replicas while MySQL has 5, and the replication process is faster (sub 10 ms replica lag)</li><li>Failover in Aurora is instantaneous. It&#39;s HA (High Availability) native.</li><li>Aurora costs more than RDS (20% more) - but is more efficient</li></ul><h3 id="aurora-high-availability-and-read-scaling" tabindex="-1">Aurora High Availability and Read Scaling <a class="header-anchor" href="#aurora-high-availability-and-read-scaling" aria-label="Permalink to “Aurora High Availability and Read Scaling”">​</a></h3><ul><li>6 copies of your data across 3 AZ:</li><li>4 copies out of 6 needed for writes</li><li>3 copies out of 6 need for reads</li><li>Self healing with peer-to-peer replication</li><li>Storage is striped across 100s of volumes</li><li>One Aurora Instance takes writes (master)</li><li>Automated failover for master in less than 30 seconds</li><li>Master + up to 15 Aurora Read Replicas serve reads</li><li>Support for Cross Region Replication</li></ul><h3 id="features-of-aurora" tabindex="-1">Features of Aurora <a class="header-anchor" href="#features-of-aurora" aria-label="Permalink to “Features of Aurora”">​</a></h3><ul><li>Automatic fail-over</li><li>Backup and Recovery</li><li>Isolation and security</li><li>Industry compliance</li><li>Push-button scaling</li><li>Automated Patching with Zero Downtime</li><li>Advanced Monitoring</li><li>Routine Maintenance</li><li>Backtrack: restore data at any point of time without using backups</li></ul><h3 id="aurora-security" tabindex="-1">Aurora Security <a class="header-anchor" href="#aurora-security" aria-label="Permalink to “Aurora Security”">​</a></h3><ul><li>Similar to RDS because uses the same engines</li><li>Encryption at rest using KMS</li><li>Automated backups, snapshots and replicas are also encrypted</li><li>Encryption in flight using SSL (same process as MySQL or Postgres)</li><li>Possibility to authenticate using IAM token (same method as RDS)</li><li>You are responsible for protecting the instance with security groups</li><li>You can&#39;t SSH</li></ul><h3 id="create-a-aurora-database" tabindex="-1">Create a Aurora database <a class="header-anchor" href="#create-a-aurora-database" aria-label="Permalink to “Create a Aurora database”">​</a></h3><p>Steps:</p><ol><li><p>Goto RDS</p></li><li><p>Create database</p></li><li><p>Choose a database creation method:</p><ul><li>Standard create</li><li>Easy create (uses predefined configurations)</li></ul></li><li><p>Engine options: Amazon Aurora (not available in Free-tier)</p></li><li><p>Select the edition and version of the database</p><ul><li>Capacity type: <ul><li>Provisioned (you provision and manage the server instance sizes)</li><li>Serverless (you specify the minimum and maximum amount of resources needed, and Aurora scales the capacity)</li></ul></li></ul></li><li><p>Templates:</p><ul><li>Production</li><li>Dev/Test</li></ul></li><li><p>Settings:</p><ul><li>DB cluster identifier</li><li>Credentials Settings: Master username and password</li></ul></li><li><p>DB Instance class:</p><ul><li>Memory optimized classes (includes r and x classes)</li><li>Burstable classes (includes t classes): db.t3.small (2 vCPUs, 2 GiB RAM, Netword: 2,085 Mbps)</li></ul></li><li><p>Availability &amp; durability: Multi-AZ deployment: Create an Aurora Replica or Reader node in a different AZ (recommended for scaled availability)</p></li><li><p>Connectivity:</p><ul><li>VPC</li><li>Subnet Group</li><li>Public access</li><li>VPC security group</li><li>Port: 3306</li></ul></li><li><p>Database authentication:</p><ul><li>Password authentication (using database passwords as created in step 7)</li><li>Password and IAM database authentication</li></ul></li><li><p>Additional configuration:</p><ul><li>Database options: Initial database name</li><li>Backup: Enable automated backups (snapshots)</li><li>Backup retention period (0 - 35 days)</li><li>Backup window (when the backup should happen)</li><li>Monitoring</li><li>Logging to CloudWatch</li><li>Maintenance: Enable auto minor version upgrade</li><li>Deletion protection (protects database from being deleted accidentally)</li></ul></li></ol><h2 id="amazon-elasticache-overview" tabindex="-1">Amazon ElastiCache Overview <a class="header-anchor" href="#amazon-elasticache-overview" aria-label="Permalink to “Amazon ElastiCache Overview”">​</a></h2><ul><li>The same way RDS is to get managed Relational Databases...</li><li>ElastiCache is to get managed Redis or Memcached</li><li>Caches are in-memory databases with really high performance, low latency</li><li>Helps reduce load off of databases for read intensive workloads</li><li>Helps make your application stateless</li><li>AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups</li><li>Using ElastiCache involves heavy application code changes</li></ul><h3 id="solution-architecture-db-cache" tabindex="-1">Solution Architecture - DB Cache <a class="header-anchor" href="#solution-architecture-db-cache" aria-label="Permalink to “Solution Architecture - DB Cache”">​</a></h3><ul><li>Applications queries ElastiCache, if not available, get from RDS and store in ElastiCache.</li><li>Helps relieve load in RDS</li><li>Cache must have an invalidation strategy to make sure only the most current data is used in there.</li></ul><h3 id="solution-architecture-user-session-store" tabindex="-1">Solution Architecture - User Session Store <a class="header-anchor" href="#solution-architecture-user-session-store" aria-label="Permalink to “Solution Architecture - User Session Store”">​</a></h3><ul><li>User logs into any of the application</li><li>The application writes the session data into ElastiCache</li><li>The user hits another instance of our application</li><li>The instance retrieves the data and the user is already logged in</li></ul><h3 id="elasticache-redis-vs-memcached" tabindex="-1">ElastiCache - Redis vs Memcached <a class="header-anchor" href="#elasticache-redis-vs-memcached" aria-label="Permalink to “ElastiCache - Redis vs Memcached”">​</a></h3><table tabindex="0"><thead><tr><th>REDIS</th><th>MEMCACHED</th></tr></thead><tbody><tr><td>Multi AZ with Auto-Failover</td><td>Multi-node for partitioning of data (sharding)</td></tr><tr><td>Read Replicas to scale reads and have high availability</td><td>No high availability (replication)</td></tr><tr><td>Data Durability using AOF persistence</td><td>Non persistent</td></tr><tr><td>Backup and restore features</td><td>No backup and restore</td></tr><tr><td></td><td>Multi-threaded architecture</td></tr></tbody></table><h3 id="elasticache-cache-security" tabindex="-1">ElastiCache - Cache Security <a class="header-anchor" href="#elasticache-cache-security" aria-label="Permalink to “ElastiCache - Cache Security”">​</a></h3><ul><li>All caches in ElastiCache: <ul><li>Do not support IAM authentication</li><li>IAM policies on ElastiCache are only used for AWS API-level security</li></ul></li><li>Redis AUTH <ul><li>You can set a &quot;password/token&quot; when you create a Redis cluster</li><li>This is an extra level of security for your cache (on top of security groups)</li><li>Support SSL in flight encryption</li></ul></li><li>Memcached <ul><li>Supports SASL-based authentication (advanced)</li></ul></li></ul><h3 id="elasticache-replication-cluster-mode-disabled" tabindex="-1">ElastiCache Replication: Cluster Mode Disabled <a class="header-anchor" href="#elasticache-replication-cluster-mode-disabled" aria-label="Permalink to “ElastiCache Replication: Cluster Mode Disabled”">​</a></h3><ul><li>One primary node, up to 5 replicas</li><li>Asynchronous Replication</li><li>The primary node is used for read/write</li><li>The other nodes are read-only</li><li>One shard, all nodes have all the data</li><li>Guard against data loss if node failure</li><li>Multi-AZ enabled by default for failover</li><li>Helpful to scale read performance</li></ul><h3 id="elasticache-replication-cluster-mode-enabled" tabindex="-1">ElastiCache Replication: Cluster Mode Enabled <a class="header-anchor" href="#elasticache-replication-cluster-mode-enabled" aria-label="Permalink to “ElastiCache Replication: Cluster Mode Enabled”">​</a></h3><ul><li>Data is partitioned across shards (helpful to scale writes)</li><li>Each shard has a primary and up to 5 replica nodes (same concept as before)</li><li>Multi-AZ capability</li><li>Up to 500 nodes per cluster: <ul><li>500 shards with single master</li><li>250 shards with 1 master and 1 replica</li><li>...</li><li>83 shards with one master and 5 replicas</li></ul></li></ul><h3 id="caching-implementation-considerations" tabindex="-1">Caching Implementation Considerations <a class="header-anchor" href="#caching-implementation-considerations" aria-label="Permalink to “Caching Implementation Considerations”">​</a></h3><ul><li>Read more at: <a href="https://aws.amazon.com/caching/implementation-considerations/" target="_blank" rel="noreferrer">AWS caching implementation</a></li><li>Is it safe to cache data? Data may be out of date, eventually consistent</li><li>Is caching effective for that data? <ul><li>Pattern: data changing slowly, few keys are frequently needed</li><li>Anti patterns: data changing rapidly, all large key space frequently needed</li></ul></li><li>Is data structured well for caching? <ul><li>example: key value caching, or caching of aggregations results</li></ul></li><li>Which caching design pattern is the most appropriate?</li></ul><ol><li><p>Lazy Loading / Cache-Aside / Lazy Population</p><ul><li>Pros <ul><li>Only requested data is cached (the cache isn&#39;t filled up with unused data)</li><li>Node failures are not fatal (just increased latency to warm the cache)</li></ul></li><li>Cons <ul><li>Cache miss penalty that results in 3 round trips, noticeable delay for that request</li><li>Stale data: data can be updated in the database and outdated in the cache</li></ul></li></ul><p><em>Example:</em></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light vitesse-dark" style="--shiki-light:#24292e;--shiki-dark:#dbd7caee;--shiki-light-bg:#fff;--shiki-dark-bg:#121212;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#CB7676;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#80A665;"> get_user</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;">    # Check the cache</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">    record </span><span style="--shiki-light:#D73A49;--shiki-dark:#666666;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> cache</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">get</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#4D9375;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record </span><span style="--shiki-light:#D73A49;--shiki-dark:#CB7676;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#4D9375;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;">        # Run a DB query</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">        record </span><span style="--shiki-light:#D73A49;--shiki-dark:#666666;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> db</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">query</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D;">select * from users where id = ?</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;">        # Populate the cache</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">        cache</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">ser</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#4D9375;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#4D9375;">    else</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#4D9375;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;"># App code</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user </span><span style="--shiki-light:#D73A49;--shiki-dark:#666666;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> get_user</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#4C9A91;">19</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span></code></pre></div></li><li><p>Write Through - Add or Update cache when database is updated</p><ul><li>Pros: <ul><li>Data in cache is never stale, reads are quick</li><li>Write penalty vs Read penalty (each write requires 2 calls)</li></ul></li><li>Cons: <ul><li>Missing Data until it is added / updated in the DB. Mitigation is to implement Lazy Loading strategy as well</li><li>Cache churn - a lot of the data will never be read RDS</li></ul></li></ul><p><em>Example:</em></p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light vitesse-dark" style="--shiki-light:#24292e;--shiki-dark:#dbd7caee;--shiki-light-bg:#fff;--shiki-dark-bg:#121212;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#CB7676;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#80A665;"> save_user</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> values</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;">    # Save to DB</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">    record </span><span style="--shiki-light:#D73A49;--shiki-dark:#666666;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> db</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">query</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D;">update users ... where id = ?</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> values</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;">    # Push into cache</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">    cache</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">set</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user_id</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#4D9375;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> record</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#758575DD;"># App code</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;">user </span><span style="--shiki-light:#D73A49;--shiki-dark:#666666;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#DBD7CAEE;"> save_user</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#4C9A91;">17</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;"> {</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D;">name</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D;">Nate Dogg</span><span style="--shiki-light:#032F62;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#666666;">})</span></span></code></pre></div></li><li><p>Cache Evictions and Time-to-live (TTL)</p><ul><li>Cache eviction can occur in three ways: <ul><li>You delete the item explicitly in the cache</li><li>Item is evicted because the memory is full and it&#39;s not recently used (LRU)</li><li>You set an item time-to-live (or TTL)</li></ul></li><li>TTL are helpful for any kind of data: <ul><li>Leaderboards</li><li>Comments</li><li>Activity streams</li></ul></li><li>TTL can range from few seconds to hours or days</li><li>If too many evictions happen due to memory, you should scale up or out</li></ul></li></ol><p>Final words of wisdom</p><ul><li>Lazy Loading / Cache aside is easy to implement and works for many situations as a foundation, especially on the read side</li><li>Write-through is usually combined with Lazy Loading as targeted for the queries or workloads that benefit from this optimization</li><li>Setting a TTL is usually not a bad idea, except when you&#39;re using Write-through. Set it to a sensible value for your application</li><li>Only cache the data that makes sense (user profiles, blogs, etc...)</li></ul><blockquote><p>There are only two hard things in Computer Science: cache invalidation and naming things</p></blockquote>`,62)]])}var s=r(a,[[`render`,o]]);export{i as __pageData,s as default};